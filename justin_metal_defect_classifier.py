# -*- coding: utf-8 -*-
"""Justin Metal Defect Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VDyBf2mTqz0ILu0aiapl2UttoWWYUB5B

Install Modules
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""# New Section

Dataset Input
"""

from google.colab import drive
drive.mount('/content/drive')
!pwd
# %cd content/drive/MyDrive/JY Western AI Metal Defect Model/Kaggle Surface Defect Set
# !ls
# %cd 'JY Western AI Metal Defect Model'
# !ls
# !pwd
# %cd Kaggle Surface Defect Set

train_data = "/content/drive/MyDrive/JY Western AI Metal Defect Model/Kaggle Surface Defect Set/test"
test_data = "/content/drive/MyDrive/JY Western AI Metal Defect Model/Kaggle Surface Defect Set/train"
valid_data = "/content/drive/MyDrive/JY Western AI Metal Defect Model/Kaggle Surface Defect Set/valid"


train_datagen = ImageDataGenerator(
    rescale=1 / 255, # NORMALIZE DATA 
    rotation_range=50, # Appply a rotation agumentation by rotating image by n C.C.W. degrees. Useful for scratches and blotches in different orientations
    zoom_range=0.2,  # Apply random zoom to image
    horizontal_flip=True) 

# Generate batches of tensor image data with real-time data augmentation
# Effectively converts images from jpeg  to tensor flow tensor arrays
test_datagen = ImageDataGenerator(rescale=1./255)


# Flow training images in batches of 10 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        train_data,             
        target_size=(200, 200), # arbitrary target size
        batch_size=10,          # arbitrary batch size
        class_mode='categorical')

# Flow validation images in batches of 10 using test_datagen generator
validation_generator = test_datagen.flow_from_directory(
        valid_data,
        target_size=(200, 200),
        batch_size=10,
        class_mode='categorical')


# Creates a class that inherits the callback method from keras

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}): # method that cancels training
        if(logs.get('accuracy') > 0.9 ):
            print("\nReached 97.8% accuracy so cancelling training!")
            self.model.stop_training = True



#Create a sequencial model instance
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (2,2), activation='relu', input_shape=(200, 200, 3)),
    tf.keras.layers.Conv2D(32, (2,2), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(3, 3),
    tf.keras.layers.Conv2D(64, (2,2), activation='relu'),
    tf.keras.layers.Conv2D(64, (2,2), activation='relu'),
    tf.keras.layers.MaxPooling2D(3,3),
    tf.keras.layers.Conv2D(128, (2,2), activation='relu'),
    tf.keras.layers.Conv2D(128, (2,2), activation='relu'),
    tf.keras.layers.MaxPooling2D(3,3),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(6, activation='softmax') 
])
model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics=['accuracy'])
print('Compiled!')

callbacks = myCallback()

history = model.fit(train_generator,
        batch_size = 30,
        epochs=80,
        validation_data=validation_generator,
        callbacks=[callbacks],
        verbose=1, shuffle=True)

"""Liam: Your refactoring should be here
 
"""

import matplotlib.pyplot as plt # MATLAB graphing library alternative
plt.figure(1) # opens figure 1

# summarize history for accuracy  
plt.subplot(211) # add axes to current figure
plt.plot(history.history['accuracy']) # I think this displays the data from `history.history['accuracy']` in the graph as y
plt.plot(history.history['val_accuracy']) # I think this displays the data from `history.history['val_accuracy']` in the graph as x
plt.title('model accuracy') # add title to current figure 
plt.ylabel('accuracy') # add ylabel to current figure
plt.xlabel('epoch') # add xlabel to current figure
plt.legend(['train', 'test'], loc='upper left') # add legend to current figurezx
   
# summarize history for loss
# more or less the same as above
plt.subplot(212) 
plt.plot(history.history['loss'])  
plt.plot(history.history['val_loss'])  
plt.title('model loss')  
plt.ylabel('loss')  
plt.xlabel('epoch')  
plt.legend(['train', 'test'], loc='upper left')  
plt.show()

# Test Result visualization
# First, we are going to load the file names and their respective target labels into numpy array! 
from sklearn.datasets import load_files
import numpy as np

test_dir = '/content/drive/MyDrive/JY Western AI Metal Defect Model/Kaggle Surface Defect Set/test'

def load_dataset(path):
    data = load_files(path)
    files = np.array(data['filenames'])
    targets = np.array(data['target'])
    target_labels = np.array(data['target_names'])
    return files,targets,target_labels
    
x_test, y_test,target_labels = load_dataset(test_dir)

no_of_classes = len(np.unique(y_test))
no_of_classes

from keras.utils import np_utils
y_test = np_utils.to_categorical(y_test,no_of_classes)

# We just have the file names in the x set. Let's load the images and convert them into array.
from keras.preprocessing.image import array_to_img, img_to_array, load_img

def convert_image_to_array(files):
    images_as_array=[]
    for file in files:
        # Convert to Numpy Array
        images_as_array.append(img_to_array(load_img(file)))
    return images_as_array

x_test = np.array(convert_image_to_array(x_test))
print('Test set shape : ',x_test.shape)

x_test = x_test.astype('float32')/255

# Visualize test prediction.

y_pred = model.predict(x_test) 

# Random plot of sample of test images, their predicted labels, and ground truth
fig = plt.figure(figsize=(16, 9))
for i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):
    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])
    ax.imshow(np.squeeze(x_test[idx]))#"""Remove axes of length one from a."""
    pred_idx = np.argmax(y_pred[idx]) #np.argmax finds out which probability in list is the highest
    true_idx = np.argmax(y_test[idx])
    ax.set_title("{} ({})".format(target_labels[pred_idx], target_labels[true_idx]),
                 color=("green" if pred_idx == true_idx else "red"))

model.save('model90acc.h5', save_format='h5')